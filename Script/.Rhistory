library(rvest)
install.packages(mcmspatial)
require(mcmspatial)
require("mcmspatial")
install.packages("mcmspatial")
install.packages("pacman")
install.packages("plyr")
install.packages("dplyr")
install.packages("ggvis")
## p_load llama/instala-llama las librerías que se enlistan:
p_load(tidyverse, # contiene las librerías ggplot, dplyr...
rvest)# web-scraping
## llamar librerias de la sesion
require(pacman)
p_load(rio, # import/export data
tidyverse, # tidy-data
skimr, # summary data
caret) # Classification And REgression Training
batches <- html("PS1.html") %>%
html_nodes(".batch")
library(rvest)
library(stringr)
library(plyr)
library(dplyr)
library(ggvis)
library(knitr)
batches <- html("PS1.html") %>%
html_nodes(".batch")
library(rvest)
batches <- html("PS1.html") %>%
html_nodes(".batch")
options(digits = 4)
batches <- html("PS1.html") %>%
html_nodes(".batch")
batches <- read_html("PS1.html") %>%
html_nodes(".batch")
batches <- read_html("PS1.html") %>%
html_nodes(".tableHTML_header_1")
class(batches)
batches <- read_html("PS1.html") %>%
html_nodes("#tableHTML_header_1")
class(batches)
batches <- read_html("PS1.html") %>%
html_nodes("td")
batches <- read_html("PS1.html") %>%
html_nodes("table")
class(batches)
my_url = "https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
html_object = read_html(my_url)
write_xml(html_object, file="PS11.html")
library(rvest)
html_object = read_html(my_url)
write_xml(html_object, file="PS11.html")
install.packages("xml2")
install.packages("xml2")
library(xml2)
html_object = read_html(my_url)
my_url = "https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
html_object = read_html(my_url)
write_xml(html_object, file="PS11.html")
batches <- read_html("PS11.html") %>%
html_nodes("table")
install.packages("pacman")
## llamar librerias de la sesion
require(pacman)
p_load(rio, # import/export data
tidyverse, # tidy-data
skimr, # summary data
caret) # Classification And REgression Training
require(pacman)
batches <- read_html("PS11.html") %>%
html_nodes("table")
## p_load llama/instala-llama las librerías que se enlistan:
p_load(tidyverse, # contiene las librerías ggplot, dplyr...
rvest)# web-scraping
batches <- read_html("PS11.html") %>%
html_nodes("table")
batches <- read_html("PS11.html") %>%
html_nodes("td")
batches <- read_html("PS1.html") %>%
html_nodes("td")
my_url = "https://ignaciomsarmiento.github.io/GEIH2018_sample/page1"
html_object = read_html(my_url)
write_xml(html_object, file="PS11.html")
batches <- read_html("PS11.html") %>%
html_nodes("td")
install.packages("curl")
install.packages("curl")
install.packages("pacman")
install.packages("pacman")
install.packages("pacman")
## llamar librerias de la sesion
require(pacman)
p_load(rio, # import/export data
tidyverse, # tidy-data
skimr, # summary data
caret) # Classification And REgression Training
## p_load llama/instala-llama las librerías que se enlistan:
p_load(tidyverse, # contiene las librerías ggplot, dplyr...
rvest)# web-scraping
library(curl)
install.packages("downloader")
library(downloader)
library(stringr)
for (myurl in tocollect) {
filename<-paste("collected/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
for (myurl in my_url) {
filename<-paste("collected/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
for (myurl in my_url) {
filename<-paste("Documentos/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
my_url<-c("https://ignaciomsarmiento.github.io/GEIH2018_sample/page1", "https://ignaciomsarmiento.github.io/GEIH2018_sample/page2")
for (myurl in my_url) {
filename<-paste("Documentos/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
for (myurl in my_url) {
filename<-paste("Documentos/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
for (myurl in my_url) {
filename<-paste("collected/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
my_url<-c("https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html", "https://ignaciomsarmiento.github.io/GEIH2018_sample/page2.html")
for (myurl in my_url) {
filename<-paste("collected/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
#my_url<-c("https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html", "https://ignaciomsarmiento.github.io/GEIH2018_sample/page2.html")
my_url ="https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
batches <- read_html(my_url) %>%
html_nodes("td")
class(batches)
require(pacman)
p_load(tidyverse, # contiene las librerías ggplot, dplyr...
rvest)# web-scraping
browseURL("https://en.wikipedia.org/robots.txt")
# require(pacman)
# p_load(tidyverse, # contiene las librerías ggplot, dplyr...
#        rvest)# web-scraping
# browseURL("https://en.wikipedia.org/robots.txt")
vignette("rvest")
# require(pacman)
# p_load(tidyverse, # contiene las librerías ggplot, dplyr...
#        rvest)# web-scraping
# browseURL("https://en.wikipedia.org/robots.txt")
#vignette("rvest")
my_url = "https://es.wikipedia.org/wiki/Copa_Mundial_de_F%C3%BAtbol"
class(my_html)
class(my_html)
# require(pacman)
# p_load(tidyverse, # contiene las librerías ggplot, dplyr...
#        rvest)# web-scraping
# browseURL("https://en.wikipedia.org/robots.txt")
#vignette("rvest")
my_url = "https://es.wikipedia.org/wiki/Copa_Mundial_de_F%C3%BAtbol"
require(pacman)
my_html = read_html(my_url) ## leer el html de la página
my_html = read_html(my_url) ## leer el html de la página
class(my_html)
View(my_html)
my_html %>% html_elements("h2")
my_html %>% html_elements("h2") %>% html_text()
#//*[@id="Historia"]
my_html %>% html_nodes(xpath = '//*[@id="mw-content-text"]/div/p[1]')
#//*[@id="Historia"]
my_html %>% html_nodes(xpath = '//*[@id="mw-content-text"]/div/p[1]')
#//*[@id="Historia"]
my_html %>% html_nodes(xpath = '//*[@id="mw-content-text"]/div/p[1]')
my_table = my_html %>% html_table()
length(my_table)
my_table[[11]]
my_url ="https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
my_url ="https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
my_html = read_html(my_url)
my_table = my_html %>% html_table()
length(my_table)
my_url ="https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
my_html = read_html(my_url)
my_html %>% html_nodes(xpath = '//*[@id="tableHTML_header_1"]')
pg<- read_html("https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html")
html_nodes(pg, "table.table-striped") %>%
purr::map(html_table) %>%
purr::mao(as_tibble)
html_nodes(pg, "table.table-striped") %>%
purrr::map(html_table) %>%
purrr::mao(as_tibble)
html_nodes(pg, "table.table-striped") %>%
purrr::map(html_table) %>%
purrr::map(as_tibble)
html_nodes(pg, "td") %>%
purrr::map(html_table) %>%
purrr::map(as_tibble)
pg
html_nodes(pg, "table") %>%
purrr::map(html_table) %>%
purrr::map(as_tibble)
pg
install.packages("Reselenium")
install.packages("Rselenium")
install.packages("RSelenium")
library(RSelenium)
rD <- rsDriver()
remDr <- rD[["client"]]
url <-"https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
fixture <- jsonlite::read_json(url)$fixture$match
batches <- read_html("PS1.html") %>%
html_nodes("td")
View(batches)
batches
batches <- read_html("PS1.html") %>%
html_nodes("table")
class(batches)
batches
View(batches)
View(batches)
batches <- read_html("PS1.html")# %>%
#html_nodes("table")
my_table = batches %>% html_table()
batches <- read_html("PS1.html") %>%
html_table()
View(batches)
batches
install.packages(gamlr)
install.packages("gamlr")
install.packages("pacman") #Instalar librería si no cuenta con esta
library(pacman) #Llamar librería#Se cargan las librerías a usar en el presente Problem Set
p_load(caret,
Matrix,
recipes,
rio,
tidyverse,
glmnet,
dplyr,
readr,
gamlr,
tidymodels,
ggplot2,
scales,
rvest,
caret,
stringr,
boot,
caret,
modeest,
stargazer,
sf,
leaflet,
tmaptools,
class,
rgeos,
nngeo,
osmdata,
randomForest,
xgboost,
nnls,
data.table,
ranger, SuperLearner, caret)
require("tidyverse")
DTEST_H<-data.frame(readRDS("../Elementos_Guardados/DTESTHOUSE.rds"))  #Guardar las bases de datos
DTRAIN_H <- data.frame(readRDS("../Elementos_Guardados/DTRAINHOUSE.rds"))
setwd("E:/MAESTRIA UNIANDES/BIG DATA/Problem-Set-3/Script")
DTEST_H<-data.frame(readRDS("../Elementos_Guardados/DTESTHOUSE.rds"))  #Guardar las bases de datos
DTRAIN_H <- data.frame(readRDS("../Elementos_Guardados/DTRAINHOUSE.rds"))
#Se elimina la columna de precio en la base Dtest
DTEST_H<-DTEST_H%>% mutate(price = NULL)
DTEST_H<-DTEST_H%>% mutate(Medellin = ifelse(l3=="Medellín", 1,0))
DTRAIN_H<-DTRAIN_H%>% mutate(Medellin = ifelse(l3=="Medellín", 1,0))
DTEST_H<-DTEST_H%>% mutate(Apto = ifelse(property_type=="Apartamento", 1,0))
DTRAIN_H<-DTRAIN_H%>% mutate(Apto = ifelse(property_type=="Apartamento", 1,0))
DTEST<-data.frame(readRDS("../Elementos_Guardados/test.rds")) #Se importa el archivo original enviado por el profesor, para tomar de referencia el orden del property ID
Prueba_1<-data.frame(readRDS("../Elementos_Guardados/test_hogares.rds"))
data2 <- read_csv("../Elementos_Guardados/submission_template.csv")
View(data2)
View(data2)
table(data2$Pobre_classification)
table(data2$Pobre_inncome)
Variable_importance<-modelo3_forestc$importance
DTEST_H<-DTEST_H%>% mutate(Medellin = ifelse(l3=="Medellín", 1,0))
DTRAIN_H<-DTRAIN_H%>% mutate(Medellin = ifelse(l3=="Medellín", 1,0))
DTEST_H<-DTEST_H%>% mutate(Apto = ifelse(property_type=="Apartamento", 1,0))
DTRAIN_H<-DTRAIN_H%>% mutate(Apto = ifelse(property_type=="Apartamento", 1,0))
DTEST<-data.frame(readRDS("../Elementos_Guardados/test.rds")) #Se importa el archivo original enviado por el profesor, para tomar de referencia el orden del property ID
set.seed(10101)
modelo3_forest <- randomForest(
price ~ Medellin + Apto + parqueaderoT + ascensorT + bathrooms+habitaciones+min_dist_bar_+min_dist_transp_+min_dist_park+surface_new_3,
data = DTRAIN_H,
num.trees = 5,
write.forest = TRUE
)
modelo3_forestr2 <- ranger(
price ~ Medellin + Apto + parqueaderoT + ascensorT + bathrooms+habitaciones+min_dist_bar_+min_dist_transp_+min_dist_park+surface_new_3,
data = DTRAIN_H,
num.trees = 10,
write.forest = TRUE
)
Variable_importance<-modelo3_forestc$importance
Variable_importance<-modelo3_forestr2$importance
Variable_importance<-modelo3_forestr2$importance
View(modelo3_forestr2)
View(modelo3_forestr2)
modelo3_forestr2 <- ranger(
price ~ Medellin + Apto + parqueaderoT + ascensorT + bathrooms+habitaciones+min_dist_bar_+min_dist_transp_+min_dist_park+surface_new_3,
data = DTRAIN_H,
num.trees = 1000,
write.forest = TRUE
)
View(modelo3_forestr2)
View(modelo3_forestr2)
