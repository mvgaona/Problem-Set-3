library(rvest)
install.packages(mcmspatial)
require(mcmspatial)
require("mcmspatial")
install.packages("mcmspatial")
install.packages("pacman")
install.packages("plyr")
install.packages("dplyr")
install.packages("ggvis")
## p_load llama/instala-llama las librerías que se enlistan:
p_load(tidyverse, # contiene las librerías ggplot, dplyr...
rvest)# web-scraping
## llamar librerias de la sesion
require(pacman)
p_load(rio, # import/export data
tidyverse, # tidy-data
skimr, # summary data
caret) # Classification And REgression Training
batches <- html("PS1.html") %>%
html_nodes(".batch")
library(rvest)
library(stringr)
library(plyr)
library(dplyr)
library(ggvis)
library(knitr)
batches <- html("PS1.html") %>%
html_nodes(".batch")
library(rvest)
batches <- html("PS1.html") %>%
html_nodes(".batch")
options(digits = 4)
batches <- html("PS1.html") %>%
html_nodes(".batch")
batches <- read_html("PS1.html") %>%
html_nodes(".batch")
batches <- read_html("PS1.html") %>%
html_nodes(".tableHTML_header_1")
class(batches)
batches <- read_html("PS1.html") %>%
html_nodes("#tableHTML_header_1")
class(batches)
batches <- read_html("PS1.html") %>%
html_nodes("td")
batches <- read_html("PS1.html") %>%
html_nodes("table")
class(batches)
my_url = "https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
html_object = read_html(my_url)
write_xml(html_object, file="PS11.html")
library(rvest)
html_object = read_html(my_url)
write_xml(html_object, file="PS11.html")
install.packages("xml2")
install.packages("xml2")
library(xml2)
html_object = read_html(my_url)
my_url = "https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
html_object = read_html(my_url)
write_xml(html_object, file="PS11.html")
batches <- read_html("PS11.html") %>%
html_nodes("table")
install.packages("pacman")
## llamar librerias de la sesion
require(pacman)
p_load(rio, # import/export data
tidyverse, # tidy-data
skimr, # summary data
caret) # Classification And REgression Training
require(pacman)
batches <- read_html("PS11.html") %>%
html_nodes("table")
## p_load llama/instala-llama las librerías que se enlistan:
p_load(tidyverse, # contiene las librerías ggplot, dplyr...
rvest)# web-scraping
batches <- read_html("PS11.html") %>%
html_nodes("table")
batches <- read_html("PS11.html") %>%
html_nodes("td")
batches <- read_html("PS1.html") %>%
html_nodes("td")
my_url = "https://ignaciomsarmiento.github.io/GEIH2018_sample/page1"
html_object = read_html(my_url)
write_xml(html_object, file="PS11.html")
batches <- read_html("PS11.html") %>%
html_nodes("td")
install.packages("curl")
install.packages("curl")
install.packages("pacman")
install.packages("pacman")
install.packages("pacman")
## llamar librerias de la sesion
require(pacman)
p_load(rio, # import/export data
tidyverse, # tidy-data
skimr, # summary data
caret) # Classification And REgression Training
## p_load llama/instala-llama las librerías que se enlistan:
p_load(tidyverse, # contiene las librerías ggplot, dplyr...
rvest)# web-scraping
library(curl)
install.packages("downloader")
library(downloader)
library(stringr)
for (myurl in tocollect) {
filename<-paste("collected/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
for (myurl in my_url) {
filename<-paste("collected/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
for (myurl in my_url) {
filename<-paste("Documentos/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
my_url<-c("https://ignaciomsarmiento.github.io/GEIH2018_sample/page1", "https://ignaciomsarmiento.github.io/GEIH2018_sample/page2")
for (myurl in my_url) {
filename<-paste("Documentos/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
for (myurl in my_url) {
filename<-paste("Documentos/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
for (myurl in my_url) {
filename<-paste("collected/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
my_url<-c("https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html", "https://ignaciomsarmiento.github.io/GEIH2018_sample/page2.html")
for (myurl in my_url) {
filename<-paste("collected/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
#my_url<-c("https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html", "https://ignaciomsarmiento.github.io/GEIH2018_sample/page2.html")
my_url ="https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
batches <- read_html(my_url) %>%
html_nodes("td")
class(batches)
require(pacman)
p_load(tidyverse, # contiene las librerías ggplot, dplyr...
rvest)# web-scraping
browseURL("https://en.wikipedia.org/robots.txt")
# require(pacman)
# p_load(tidyverse, # contiene las librerías ggplot, dplyr...
#        rvest)# web-scraping
# browseURL("https://en.wikipedia.org/robots.txt")
vignette("rvest")
# require(pacman)
# p_load(tidyverse, # contiene las librerías ggplot, dplyr...
#        rvest)# web-scraping
# browseURL("https://en.wikipedia.org/robots.txt")
#vignette("rvest")
my_url = "https://es.wikipedia.org/wiki/Copa_Mundial_de_F%C3%BAtbol"
class(my_html)
class(my_html)
# require(pacman)
# p_load(tidyverse, # contiene las librerías ggplot, dplyr...
#        rvest)# web-scraping
# browseURL("https://en.wikipedia.org/robots.txt")
#vignette("rvest")
my_url = "https://es.wikipedia.org/wiki/Copa_Mundial_de_F%C3%BAtbol"
require(pacman)
my_html = read_html(my_url) ## leer el html de la página
my_html = read_html(my_url) ## leer el html de la página
class(my_html)
View(my_html)
my_html %>% html_elements("h2")
my_html %>% html_elements("h2") %>% html_text()
#//*[@id="Historia"]
my_html %>% html_nodes(xpath = '//*[@id="mw-content-text"]/div/p[1]')
#//*[@id="Historia"]
my_html %>% html_nodes(xpath = '//*[@id="mw-content-text"]/div/p[1]')
#//*[@id="Historia"]
my_html %>% html_nodes(xpath = '//*[@id="mw-content-text"]/div/p[1]')
my_table = my_html %>% html_table()
length(my_table)
my_table[[11]]
my_url ="https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
my_url ="https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
my_html = read_html(my_url)
my_table = my_html %>% html_table()
length(my_table)
my_url ="https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
my_html = read_html(my_url)
my_html %>% html_nodes(xpath = '//*[@id="tableHTML_header_1"]')
pg<- read_html("https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html")
html_nodes(pg, "table.table-striped") %>%
purr::map(html_table) %>%
purr::mao(as_tibble)
html_nodes(pg, "table.table-striped") %>%
purrr::map(html_table) %>%
purrr::mao(as_tibble)
html_nodes(pg, "table.table-striped") %>%
purrr::map(html_table) %>%
purrr::map(as_tibble)
html_nodes(pg, "td") %>%
purrr::map(html_table) %>%
purrr::map(as_tibble)
pg
html_nodes(pg, "table") %>%
purrr::map(html_table) %>%
purrr::map(as_tibble)
pg
install.packages("Reselenium")
install.packages("Rselenium")
install.packages("RSelenium")
library(RSelenium)
rD <- rsDriver()
remDr <- rD[["client"]]
url <-"https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
fixture <- jsonlite::read_json(url)$fixture$match
batches <- read_html("PS1.html") %>%
html_nodes("td")
View(batches)
batches
batches <- read_html("PS1.html") %>%
html_nodes("table")
class(batches)
batches
View(batches)
View(batches)
batches <- read_html("PS1.html")# %>%
#html_nodes("table")
my_table = batches %>% html_table()
batches <- read_html("PS1.html") %>%
html_table()
View(batches)
batches
install.packages(gamlr)
install.packages("gamlr")
install.packages("pacman") #Instalar librería si no cuenta con esta
library(pacman) #Llamar librería#Se cargan las librerías a usar en el presente Problem Set
p_load(caret,
Matrix,
recipes,
rio, #Instalar librerías que falten
tidyverse,
glmnet,
dplyr,
readr,
gamlr,
tidymodels,
ggplot2,
scales,
ggpubr,
skimr,
rvest,
caret,
stringr,
boot,
caret,
modeest,
recipes,
glmnet,
stargazer,
pROC,
sf,
leaflet,
tmaptools,
osmdata)
rm(list = ls()) #Limpia las variables que existan al momento de correr el código
###Base de datos Problem set 2
library(readr)
#Se debe poner el directorio de donde está el script:
#Session-> Set Working directory -> To source file location, para lo cual se debe descargar el repositorioDatos_test_hogares<-readRDS("../Elementos_Guardados/test_hogares.rds") #Guardar las bases de datos
DTEST<-data.frame(readRDS("../Elementos_Guardados/test.rds"))  #Guardar las bases de datos
setwd("E:/MAESTRIA UNIANDES/BIG DATA/Problem-Set-3/Script")
#Se debe poner el directorio de donde está el script:
#Session-> Set Working directory -> To source file location, para lo cual se debe descargar el repositorioDatos_test_hogares<-readRDS("../Elementos_Guardados/test_hogares.rds") #Guardar las bases de datos
DTEST<-data.frame(readRDS("../Elementos_Guardados/test.rds"))  #Guardar las bases de datos
DTRAIN <- data.frame(readRDS("../Elementos_Guardados/train.rds"))
summary(DTEST)
summary(DTRAIN)
View(DTRAIN$description)
tail(DTRAIN$description)
#Creación variable Parqueadero para train y test
Descripc_test<-DTEST$description
parqueaderoT_aux1<-str_detect( Descripc_test,"parqueadero")
parqueaderoT_aux2<-str_detect( Descripc_test,"parqueaderos")
parqueaderoT_aux3<-str_detect( Descripc_test,"parqeadero")
parqueaderoT_aux4<-str_detect( Descripc_test,"parqeaderos")
parqueaderoT_aux5<-str_detect( Descripc_test,"garaje")
parqueaderoT_aux6<-str_detect( Descripc_test,"garajes")
parqueaderoT<-ifelse(parqueaderoT_aux1==TRUE|parqueaderoT_aux2==TRUE| parqueaderoT_aux3==TRUE|parqueaderoT_aux4==TRUE|parqueaderoT_aux5==TRUE|parqueaderoT_aux6==TRUE,1,0 )
parqueaderoT<-data.frame(parqueaderoT)
summary(parqueaderoT)
parqueaderoT[is.na(parqueaderoT)] = 0
summary(parqueaderoT)
DTEST<- cbind(DTEST, parqueaderoT)
rm(parqueaderoT)
Descripc_train<-DTRAIN$description
parqueadero_aux1<-str_detect( Descripc_train,"parqueadero")
parqueadero_aux2<-str_detect( Descripc_train,"parqueaderos")
parqueadero_aux3<-str_detect( Descripc_train,"parqeadero")
parqueadero_aux4<-str_detect( Descripc_train,"parqeaderos")
parqueadero_aux5<-str_detect( Descripc_train,"garaje")
parqueadero_aux6<-str_detect( Descripc_train,"garajes")
parqueaderoT<-ifelse(parqueadero_aux1==TRUE|parqueadero_aux2==TRUE| parqueadero_aux3==TRUE|parqueadero_aux4==TRUE|parqueadero_aux5==TRUE|parqueadero_aux6==TRUE,1,0 )
parqueaderoT<-data.frame(parqueaderoT)
summary(parqueaderoT)
parqueaderoT[is.na(parqueaderoT)] = 0
View(parqueaderoT)
summary(parqueaderoT)
DTRAIN <- cbind(DTRAIN, parqueaderoT)
rm(parqueaderoT)
#Creación variable  para train y test
ascensorT_aux1<-str_detect( Descripc_test,"ascensor")
ascensorT_aux2<-str_detect( Descripc_test,"acensor")
ascensorT_aux3<-str_detect( Descripc_test,"asensor")
ascensorT_aux4<-str_detect( Descripc_test,"elevador")
ascensorT_aux5<-str_detect( Descripc_test,"ascensores")
ascensorT_aux6<-str_detect( Descripc_test,"acensores")
ascensorT_aux7<-str_detect( Descripc_test,"asensores")
ascensorT_aux8<-str_detect( Descripc_test,"elevadores")
ascensorT<-ifelse(ascensorT_aux1==TRUE|ascensorT_aux2==TRUE| ascensorT_aux3==TRUE|ascensorT_aux4==TRUE|ascensorT_aux5==TRUE|ascensorT_aux6==TRUE|ascensorT_aux7==TRUE|ascensorT_aux8==TRUE, 1,0 )
ascensorT<-data.frame(ascensorT)
summary(ascensorT)
ascensorT[is.na(ascensorT)] = 0
summary(ascensorT)
DTEST <- cbind(DTEST, ascensorT)
view(DTEST)
rm(ascensorT)
ascensor_aux1<-str_detect( Descripc_train,"ascensor")
ascensor_aux2<-str_detect( Descripc_train,"acensor")
ascensor_aux3<-str_detect( Descripc_train,"asensor")
ascensor_aux4<-str_detect( Descripc_train,"elevador")
ascensor_aux5<-str_detect( Descripc_train,"ascensores")
ascensor_aux6<-str_detect( Descripc_train,"acensores")
ascensor_aux7<-str_detect( Descripc_train,"asensores")
ascensor_aux8<-str_detect( Descripc_train,"elevadores")
ascensorT<-ifelse(ascensor_aux1==TRUE|ascensor_aux2==TRUE| ascensor_aux3==TRUE|ascensor_aux4==TRUE|ascensor_aux5==TRUE|ascensor_aux6==TRUE|ascensor_aux7==TRUE|ascensor_aux8==TRUE, 1,0 )
ascensorT<-data.frame(ascensorT)
summary(ascensorT)
ascensorT[is.na(ascensorT)] = 0
summary(ascensorT)
DTRAIN <- cbind(DTRAIN, ascensorT)
view(DTRAIN)
rm(ascensorT)
table(DTRAIN$l3)
table(DTEST$l3)
table(is.na(DTRAIN$surface_total))
table(is.na(DTRAIN$surface_covered))
DTRAIN[46,]
DTRAIN_sf <- DTRAIN %>% st_as_sf(coords = c("lon", "lat"), crs = 4326)
class(DTRAIN_sf)
#Para visualizar todas las observaciones en Bogotá y Medellín
leaflet() %>% addTiles() %>% addCircleMarkers(data=DTRAIN_sf)
#Solo observaremos 1000
leaflet() %>% addTiles() %>% addCircleMarkers(data=DTRAIN_sf[1:1000,])
#Buscar el poblado
require("tmaptools")
geocode_OSM("El poblado, Medellin")
PointElPoblado = geocode_OSM("El poblado, Medellín", as.sf=T)
PointElPoblado
PointChapinero = geocode_OSM("Chapinero, Bogotá", as.sf=T)
PointChapinero
leaflet() %>% addTiles() %>% addCircles(data=PointElPoblado)
leaflet() %>% addTiles() %>% addCircles(data=PointChapinero)
## la función addTiles adiciona la capa de OpenStreetMap
leaflet() %>% addTiles() %>% addCircles(data=PointElPoblado)
leaflet() %>% addTiles() %>% addCircles(data=PointChapinero)
#Atributos
#Puede acceder a la lista de features disponibles en OSM aquí. En R puede obtener un vector con los nombres de los features usando la función available_features():
available_features() %>% head(20)
## obtener la caja de coordenada que contiene el polígono de Medellín
opq(bbox = getbb("El poblado Medellin"))
## objeto osm
osm = opq(bbox = getbb("El poblado Medellin")) %>%
available_tags("amenity") %>% head(20)
## objeto osm
osm = opq(bbox = getbb("El poblado Medellin")) %>%
available_tags("amenity") %>% head(20)
## obtener la caja de coordenada que contiene el polígono de Medellín
opq(bbox = getbb("El poblado Medellin"))
## objeto osm
osm = opq(bbox = getbb("El poblado Medellin")) %>%
available_tags("amenity") %>% head(20)
#Buscar el poblado
require("tmaptools")
geocode_OSM("El poblado, Medellin")
PointElPoblado = geocode_OSM("El poblado, Medellín", as.sf=T)
PointElPoblado
PointChapinero = geocode_OSM("Chapinero, Bogotá", as.sf=T)
PointChapinero
leaflet() %>% addTiles() %>% addCircles(data=PointElPoblado)
leaflet() %>% addTiles() %>% addCircles(data=PointChapinero)
## la función addTiles adiciona la capa de OpenStreetMap
leaflet() %>% addTiles() %>% addCircles(data=PointElPoblado)
leaflet() %>% addTiles() %>% addCircles(data=PointChapinero)
#Atributos
#Puede acceder a la lista de features disponibles en OSM aquí. En R puede obtener un vector con los nombres de los features usando la función available_features():
available_features() %>% head(20)
## obtener la caja de coordenada que contiene el polígono de Medellín
opq(bbox = getbb("El poblado Medellin"))
## objeto osm
osm = opq(bbox = getbb("El poblado Medellin")) %>%
available_tags("amenity") %>% head(20)
