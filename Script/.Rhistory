library(rvest)
install.packages(mcmspatial)
require(mcmspatial)
require("mcmspatial")
install.packages("mcmspatial")
install.packages("pacman")
install.packages("plyr")
install.packages("dplyr")
install.packages("ggvis")
## p_load llama/instala-llama las librerías que se enlistan:
p_load(tidyverse, # contiene las librerías ggplot, dplyr...
rvest)# web-scraping
## llamar librerias de la sesion
require(pacman)
p_load(rio, # import/export data
tidyverse, # tidy-data
skimr, # summary data
caret) # Classification And REgression Training
batches <- html("PS1.html") %>%
html_nodes(".batch")
library(rvest)
library(stringr)
library(plyr)
library(dplyr)
library(ggvis)
library(knitr)
batches <- html("PS1.html") %>%
html_nodes(".batch")
library(rvest)
batches <- html("PS1.html") %>%
html_nodes(".batch")
options(digits = 4)
batches <- html("PS1.html") %>%
html_nodes(".batch")
batches <- read_html("PS1.html") %>%
html_nodes(".batch")
batches <- read_html("PS1.html") %>%
html_nodes(".tableHTML_header_1")
class(batches)
batches <- read_html("PS1.html") %>%
html_nodes("#tableHTML_header_1")
class(batches)
batches <- read_html("PS1.html") %>%
html_nodes("td")
batches <- read_html("PS1.html") %>%
html_nodes("table")
class(batches)
my_url = "https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
html_object = read_html(my_url)
write_xml(html_object, file="PS11.html")
library(rvest)
html_object = read_html(my_url)
write_xml(html_object, file="PS11.html")
install.packages("xml2")
install.packages("xml2")
library(xml2)
html_object = read_html(my_url)
my_url = "https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
html_object = read_html(my_url)
write_xml(html_object, file="PS11.html")
batches <- read_html("PS11.html") %>%
html_nodes("table")
install.packages("pacman")
## llamar librerias de la sesion
require(pacman)
p_load(rio, # import/export data
tidyverse, # tidy-data
skimr, # summary data
caret) # Classification And REgression Training
require(pacman)
batches <- read_html("PS11.html") %>%
html_nodes("table")
## p_load llama/instala-llama las librerías que se enlistan:
p_load(tidyverse, # contiene las librerías ggplot, dplyr...
rvest)# web-scraping
batches <- read_html("PS11.html") %>%
html_nodes("table")
batches <- read_html("PS11.html") %>%
html_nodes("td")
batches <- read_html("PS1.html") %>%
html_nodes("td")
my_url = "https://ignaciomsarmiento.github.io/GEIH2018_sample/page1"
html_object = read_html(my_url)
write_xml(html_object, file="PS11.html")
batches <- read_html("PS11.html") %>%
html_nodes("td")
install.packages("curl")
install.packages("curl")
install.packages("pacman")
install.packages("pacman")
install.packages("pacman")
## llamar librerias de la sesion
require(pacman)
p_load(rio, # import/export data
tidyverse, # tidy-data
skimr, # summary data
caret) # Classification And REgression Training
## p_load llama/instala-llama las librerías que se enlistan:
p_load(tidyverse, # contiene las librerías ggplot, dplyr...
rvest)# web-scraping
library(curl)
install.packages("downloader")
library(downloader)
library(stringr)
for (myurl in tocollect) {
filename<-paste("collected/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
for (myurl in my_url) {
filename<-paste("collected/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
for (myurl in my_url) {
filename<-paste("Documentos/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
my_url<-c("https://ignaciomsarmiento.github.io/GEIH2018_sample/page1", "https://ignaciomsarmiento.github.io/GEIH2018_sample/page2")
for (myurl in my_url) {
filename<-paste("Documentos/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
for (myurl in my_url) {
filename<-paste("Documentos/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
for (myurl in my_url) {
filename<-paste("collected/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
my_url<-c("https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html", "https://ignaciomsarmiento.github.io/GEIH2018_sample/page2.html")
for (myurl in my_url) {
filename<-paste("collected/", str_match(myurl, "UniqueID=(.+)")[2], ".html", sep="")
download(myurl, filename)
Sys.sleep(2)
}
#my_url<-c("https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html", "https://ignaciomsarmiento.github.io/GEIH2018_sample/page2.html")
my_url ="https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
batches <- read_html(my_url) %>%
html_nodes("td")
class(batches)
require(pacman)
p_load(tidyverse, # contiene las librerías ggplot, dplyr...
rvest)# web-scraping
browseURL("https://en.wikipedia.org/robots.txt")
# require(pacman)
# p_load(tidyverse, # contiene las librerías ggplot, dplyr...
#        rvest)# web-scraping
# browseURL("https://en.wikipedia.org/robots.txt")
vignette("rvest")
# require(pacman)
# p_load(tidyverse, # contiene las librerías ggplot, dplyr...
#        rvest)# web-scraping
# browseURL("https://en.wikipedia.org/robots.txt")
#vignette("rvest")
my_url = "https://es.wikipedia.org/wiki/Copa_Mundial_de_F%C3%BAtbol"
class(my_html)
class(my_html)
# require(pacman)
# p_load(tidyverse, # contiene las librerías ggplot, dplyr...
#        rvest)# web-scraping
# browseURL("https://en.wikipedia.org/robots.txt")
#vignette("rvest")
my_url = "https://es.wikipedia.org/wiki/Copa_Mundial_de_F%C3%BAtbol"
require(pacman)
my_html = read_html(my_url) ## leer el html de la página
my_html = read_html(my_url) ## leer el html de la página
class(my_html)
View(my_html)
my_html %>% html_elements("h2")
my_html %>% html_elements("h2") %>% html_text()
#//*[@id="Historia"]
my_html %>% html_nodes(xpath = '//*[@id="mw-content-text"]/div/p[1]')
#//*[@id="Historia"]
my_html %>% html_nodes(xpath = '//*[@id="mw-content-text"]/div/p[1]')
#//*[@id="Historia"]
my_html %>% html_nodes(xpath = '//*[@id="mw-content-text"]/div/p[1]')
my_table = my_html %>% html_table()
length(my_table)
my_table[[11]]
my_url ="https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
my_url ="https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
my_html = read_html(my_url)
my_table = my_html %>% html_table()
length(my_table)
my_url ="https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
my_html = read_html(my_url)
my_html %>% html_nodes(xpath = '//*[@id="tableHTML_header_1"]')
pg<- read_html("https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html")
html_nodes(pg, "table.table-striped") %>%
purr::map(html_table) %>%
purr::mao(as_tibble)
html_nodes(pg, "table.table-striped") %>%
purrr::map(html_table) %>%
purrr::mao(as_tibble)
html_nodes(pg, "table.table-striped") %>%
purrr::map(html_table) %>%
purrr::map(as_tibble)
html_nodes(pg, "td") %>%
purrr::map(html_table) %>%
purrr::map(as_tibble)
pg
html_nodes(pg, "table") %>%
purrr::map(html_table) %>%
purrr::map(as_tibble)
pg
install.packages("Reselenium")
install.packages("Rselenium")
install.packages("RSelenium")
library(RSelenium)
rD <- rsDriver()
remDr <- rD[["client"]]
url <-"https://ignaciomsarmiento.github.io/GEIH2018_sample/page1.html"
fixture <- jsonlite::read_json(url)$fixture$match
batches <- read_html("PS1.html") %>%
html_nodes("td")
View(batches)
batches
batches <- read_html("PS1.html") %>%
html_nodes("table")
class(batches)
batches
View(batches)
View(batches)
batches <- read_html("PS1.html")# %>%
#html_nodes("table")
my_table = batches %>% html_table()
batches <- read_html("PS1.html") %>%
html_table()
View(batches)
batches
install.packages(gamlr)
install.packages("gamlr")
setwd("E:/MAESTRIA UNIANDES/BIG DATA/Problem-Set-3/Script")
install.packages("pacman") #Instalar librería si no cuenta con esta
library(pacman) #Llamar librería
#Se cargan las librerías a usar en el presente Problem Set
p_load(caret,
Matrix,
recipes,
rio, #Instalar librerías que falten
tidyverse,
glmnet,
dplyr,
readr,
gamlr,
tidymodels,
ggplot2,
scales,
ggpubr,
skimr,
rvest,
caret,
stringr,
boot,
caret,
modeest,
recipes,
glmnet,
stargazer,
pROC)
rm(list = ls()) #Limpia las variables que existan al momento de correr el código
###Base de datos Problem set 2
library(readr)
#Se debe poner el directorio de donde está el script:
#Session-> Set Working directory -> To source file location, para lo cual se debe descargar el repositorioDatos_test_hogares<-readRDS("../Elementos_Guardados/test_hogares.rds") #Guardar las bases de datos
DTEST<-data.frame(readRDS("../Elementos_Guardados/test.rds"))  #Guardar las bases de datos
setwd("E:/MAESTRIA UNIANDES/BIG DATA/Problem-Set-3/Script")
#Se debe poner el directorio de donde está el script:
#Session-> Set Working directory -> To source file location, para lo cual se debe descargar el repositorioDatos_test_hogares<-readRDS("../Elementos_Guardados/test_hogares.rds") #Guardar las bases de datos
DTEST<-data.frame(readRDS("../Elementos_Guardados/test.rds"))  #Guardar las bases de datos
setwd("E:/MAESTRIA UNIANDES/BIG DATA/Problem-Set-3/Script")
#Se debe poner el directorio de donde está el script:
#Session-> Set Working directory -> To source file location, para lo cual se debe descargar el repositorioDatos_test_hogares<-readRDS("../Elementos_Guardados/test_hogares.rds") #Guardar las bases de datos
DTEST<-data.frame(readRDS("../Elementos_Guardados/test.rds"))  #Guardar las bases de datos
DTRAIN <- data.frame(readRDS("../Elementos_Guardados/train.rds"))
#Se debe poner el directorio de donde está el script:
#Session-> Set Working directory -> To source file location, para lo cual se debe descargar el repositorioDatos_test_hogares<-readRDS("../Elementos_Guardados/test_hogares.rds") #Guardar las bases de datos
DTEST<-data.frame(readRDS("../Elementos_Guardados/test.rds"))  #Guardar las bases de datos
DTRAIN <- data.frame(readRDS("../Elementos_Guardados/train.rds"))
View(DTEST)
View(DTEST)
View(DTRAIN)
View(DTRAIN)
